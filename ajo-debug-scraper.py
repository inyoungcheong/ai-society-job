#!/usr/bin/env python3
"""
AJO Debug Scraper - ì‹¤ì œ ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡° íŒŒì•…
"""

import requests
from bs4 import BeautifulSoup
import time

def debug_ajo_structure():
    """AJO ì‚¬ì´íŠ¸ êµ¬ì¡° ë””ë²„ê¹…"""
    
    session = requests.Session()
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
    })
    
    # 1. ë©”ì¸ jobs í˜ì´ì§€ í™•ì¸
    print("ğŸ” Step 1: Checking main jobs page...")
    main_url = "https://academicjobsonline.org/ajo/jobs"
    
    try:
        response = session.get(main_url, timeout=10)
        print(f"Status Code: {response.status_code}")
        print(f"URL: {response.url}")
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # í˜ì´ì§€ ì œëª© í™•ì¸
            title = soup.find('title')
            print(f"Page Title: {title.get_text() if title else 'No title found'}")
            
            # ê°€ëŠ¥í•œ job listing í´ë˜ìŠ¤ë“¤ ì°¾ê¸°
            print("\nğŸ” Looking for job listings...")
            
            # ë‹¤ì–‘í•œ í´ë˜ìŠ¤ëª… ì‹œë„
            possible_selectors = [
                'div.job-listing',
                'tr.job-row', 
                'div.listing',
                'div.job',
                'table tr',
                'div[class*="job"]',
                'tr[class*="job"]'
            ]
            
            for selector in possible_selectors:
                elements = soup.select(selector)
                if elements:
                    print(f"âœ… Found {len(elements)} elements with selector: {selector}")
                    
                    # ì²« ë²ˆì§¸ ìš”ì†Œì˜ êµ¬ì¡° ì¶œë ¥
                    if elements:
                        print("Sample element structure:")
                        print(elements[0].prettify()[:500] + "...")
                        break
                else:
                    print(f"âŒ No elements found with: {selector}")
            
            # ì „ì²´ HTML êµ¬ì¡° ì¼ë¶€ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
            print(f"\nğŸ“„ Page HTML sample:")
            print(response.text[:1000] + "...")
            
        else:
            print(f"âŒ Failed to access main page: {response.status_code}")
            
    except Exception as e:
        print(f"âŒ Error accessing main page: {e}")
    
    # 2. ê²€ìƒ‰ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    print(f"\nğŸ” Step 2: Testing search functionality...")
    
    search_urls = [
        "https://academicjobsonline.org/ajo/jobs?keyword=computer+science",
        "https://academicjobsonline.org/ajo/jobs/computer-science",
        "https://academicjobsonline.org/ajo/COMP",  # ì»´í“¨í„° ê³¼í•™ ì¹´í…Œê³ ë¦¬
    ]
    
    for search_url in search_urls:
        try:
            print(f"\nTrying: {search_url}")
            response = session.get(search_url, timeout=10)
            print(f"Status: {response.status_code}")
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # ê²°ê³¼ ê°œìˆ˜ ì°¾ê¸°
                result_indicators = soup.find_all(text=lambda text: text and ('job' in text.lower() or 'position' in text.lower()))
                if result_indicators:
                    print(f"Found text mentioning jobs: {result_indicators[:3]}")
                
        except Exception as e:
            print(f"âŒ Error with {search_url}: {e}")
        
        time.sleep(1)

def check_robots_txt():
    """robots.txt í™•ì¸"""
    print("\nğŸ¤– Checking robots.txt...")
    try:
        response = requests.get("https://academicjobsonline.org/robots.txt", timeout=5)
        if response.status_code == 200:
            print("Robots.txt content:")
            print(response.text[:500])
        else:
            print(f"No robots.txt found: {response.status_code}")
    except Exception as e:
        print(f"Error checking robots.txt: {e}")

def simple_ajo_test():
    """ê°„ë‹¨í•œ AJO ì ‘ê·¼ í…ŒìŠ¤íŠ¸"""
    print("ğŸŒ Simple AJO access test...")
    
    try:
        response = requests.get("https://academicjobsonline.org", timeout=10)
        print(f"Main site status: {response.status_code}")
        print(f"Response length: {len(response.text)}")
        
        if "Academic Jobs Online" in response.text:
            print("âœ… Successfully accessed AJO!")
        else:
            print("âš ï¸ Might be accessing wrong site or blocked")
            
    except Exception as e:
        print(f"âŒ Cannot access AJO: {e}")

if __name__ == "__main__":
    print("ğŸ•µï¸ AJO Structure Debug Tool")
    print("=" * 50)
    
    simple_ajo_test()
    check_robots_txt() 
    debug_ajo_structure()